{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vascotreis/Cat_identifier/blob/main/catbreed_classification_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##*Installing the necessary libraries for this project*##"
      ],
      "metadata": {
        "id": "Xg9jPXhzvuuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Data set was taken from https://www.robots.ox.ac.uk/~vgg/data/pets/"
      ],
      "metadata": {
        "id": "iqgfacqGJdqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install imageio\n",
        "#!pip install scikit-image"
      ],
      "metadata": {
        "id": "DwYh4jPIjebT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJiYkz-58jd8",
        "outputId": "df57343a-3da4-453a-e000-57d529351bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##*connecting the notebook with your google drive*##\n",
        "###*This is done so that I can access the data set that is stored in google drive*###"
      ],
      "metadata": {
        "id": "iSBGgkFDv1Wi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsgbJirvaocN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd34a80e-b0e2-4c11-f4b1-622a28f41b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##*Declaring the path of the files in the drive*##\n",
        "##*Also the path where the model will be saved*##"
      ],
      "metadata": {
        "id": "DSME9refwO3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/Test_the_Keras/Projecto/CATS 2/\"\n",
        "model_dir='/content/drive/MyDrive/Test_the_Keras/Projecto/'"
      ],
      "metadata": {
        "id": "ezDxm97gbArS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##*Importing all the necessary libraries and modules for the program*##"
      ],
      "metadata": {
        "id": "uRvfCKPWwdZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import VGG16\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from imageio import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "Ko_5jdUcbejR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##*Creating an empty list to store all the name of breeds*##"
      ],
      "metadata": {
        "id": "nEC4HL2Vw4p7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list to store the breeds\n",
        "breeds = []"
      ],
      "metadata": {
        "id": "SoraEzFGbfzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##*The naming convention of the dataset is as follows*##\n",
        "####BreedName_number.jpg###\n",
        "###the below code splits the name into two portions### \n",
        "####*1. before the   \"_\"*####\n",
        "####*2. After the    \"_\"*#### \n",
        "###all unique strings before \"_\" are appended to the list of breeds###"
      ],
      "metadata": {
        "id": "iNMGSWPlxFXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through the images in the folder\n",
        "for image in os.listdir(path):\n",
        "    if image.endswith('.jpg') or image.endswith('.jpeg') or image.endswith('.png'):\n",
        "        # extract the breed name from the image name\n",
        "        breed = image.split(\"_\")[0]\n",
        "        # add the breed to the list if it is not already in the list\n",
        "        if breed not in breeds:\n",
        "            breeds.append(breed)\n",
        "\n",
        "\n",
        "print(breeds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TG9tdDjblYV",
        "outputId": "e4b0070d-eb8d-4348-f3dd-539638c6f70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bengal', 'Sphynx', 'Bombay', 'Egyptian', 'Persian', 'Ragdoll', 'Siamese', 'Maine', 'Birman', 'Abyssinian', 'Russian', 'British']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###you can see that there are 12 breeds in the given daaset###"
      ],
      "metadata": {
        "id": "x7BQCcEByUSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*creating a dictionary to map breed to an integer for computation purposes*###\n",
        "\n",
        "> Bloco com avan√ßo\n",
        "\n"
      ],
      "metadata": {
        "id": "QHgohwbgyeVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dictionary to map breed names to integers\n",
        "breed_mapping = {breed: i for i, breed in enumerate(breeds)}"
      ],
      "metadata": {
        "id": "_1I0UGCxbxzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(breed_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQtRoRrJAUbX",
        "outputId": "e84a099c-f3f7-452f-f567-9830255c1c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Bengal': 0, 'Sphynx': 1, 'Bombay': 2, 'Egyptian': 3, 'Persian': 4, 'Ragdoll': 5, 'Siamese': 6, 'Maine': 7, 'Birman': 8, 'Abyssinian': 9, 'Russian': 10, 'British': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*Two empty lists are created for storing the image data and the respective labels*###"
      ],
      "metadata": {
        "id": "CDQuyk-_ysiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the data and labels arrays\n",
        "data = []\n",
        "labels = []"
      ],
      "metadata": {
        "id": "gPtvKd3IcOAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*Images in the dataset may be of varying size and resolution, to create a model for prediction using Neural Networks all the images should be of a standard size*###\n",
        "####*- resolution of 224 x 224 was chosen for this project, because all research I did images I saw it seams a universal size and also this works well with the VGG16 model I plan to test for this project*#### \n",
        "####*- all the images should be resized to this resolution before storing into data list*####\n"
      ],
      "metadata": {
        "id": "ZukCe0IrzMEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through the images in the folder\n",
        "for image in os.listdir(path):\n",
        "    if image.endswith('.jpg') or image.endswith('.jpeg') or image.endswith('.png'):\n",
        "        # load the image\n",
        "        img = cv2.imread(path+image)\n",
        "        # resize the image\n",
        "        try:\n",
        "          # resizing the image\n",
        "          img = cv2.resize(img, (224, 224))\n",
        "          # add the image to the data list\n",
        "          data.append(img)\n",
        "          # extract the breed name from the image name\n",
        "          breed = image.split(\"_\")[0]\n",
        "          # add the corresponding label to the labels list\n",
        "          labels.append(breed_mapping[breed])\n",
        "        except Exception as e:\n",
        "          print(f\"could not resize {image}\")\n",
        "       \n",
        "\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkx-whKPi6W6",
        "outputId": "1109b3f6-9e5b-4b28-a505-f65617452d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "could not resize Egyptian_Mau_191.jpg\n",
            "could not resize Egyptian_Mau_177.jpg\n",
            "could not resize Egyptian_Mau_139.jpg\n",
            "could not resize Egyptian_Mau_145.jpg\n",
            "could not resize Abyssinian_34.jpg\n",
            "could not resize Egyptian_Mau_167.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete all of this images so it wont scruew my code"
      ],
      "metadata": {
        "id": "5N-bgutlPciH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*please note that not all images could be resized, some of the images which are shown above were not resizable hence we had to ignore those*### "
      ],
      "metadata": {
        "id": "Iul1_t5h0NTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"total nnumber of images available : {len(data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzJa-w_m25TR",
        "outputId": "ced8dbda-585d-4357-eebf-16998e55a3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total nnumber of images available : 2402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*In order to train the model we require the data and labels as numpy arrays*###\n",
        " ###*Numpy arrays are more compact than python lists, which uses less memory. Numpy is also not just more efficient but convienient. There are a lot of vector and matrix operations in Numpy. There are also things built into Numpy such as FFT's, convolutions, statistics, histograms, etc*###\n",
        "####*- hence converting the python lists : data and labels in to numpy arrays*#### "
      ],
      "metadata": {
        "id": "OfYjIA9f0u3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "print(f\"Data : {data.shape} , lables : {labels.shape}\")"
      ],
      "metadata": {
        "id": "kBzxnXhKnQ7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb607dc-c258-4e09-b7b8-34a42fd44392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data : (2402, 224, 224, 3) , lables : (2402,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*In order to make sure that the training set as well as the test set have representatives of all Breeds the data was split into numerous sample sizes randomly*###\n",
        "\n",
        "####*Train and test set are later gathered from this randomized pool of data*####\n",
        "\n",
        "# I saw this while researcho Keras \n",
        "# Stratified ShuffleSplit cross-validator. Provides train/test indices to split data in train/test sets. This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.#. "
      ],
      "metadata": {
        "id": "paGsUcAy1XKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*In order to make sure that the training set as well as the test set have representatives of all Breeds the data was split into numerous sample sizes randomly*###\n",
        "\n",
        "####*Train and test set are later gathered from this randomized pool of data*####"
      ],
      "metadata": {
        "id": "7WqnCo1BXS6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# Your data and labels stored in X and y respectively\n",
        "X = data\n",
        "y = labels\n",
        "\n",
        "# Define the number of splits you want\n",
        "n_splits = 15\n",
        "\n",
        "# Create an instance of the StratifiedShuffleSplit class\n",
        "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.15, random_state=42)\n",
        "\n",
        "# Use the split method to get the train and test indices\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "print(f\"training set: {len(X_train)} , test set : {len(X_test)}\")"
      ],
      "metadata": {
        "id": "tpbhXorM7AgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb010c5d-56b1-4cd6-d7c2-3eecc4336658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set: 2041 , test set : 361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 model, Will researching I found this model and seemed easy to apply so I used some snipets from this web site https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c and ChatGBT to compose my code"
      ],
      "metadata": {
        "id": "rZ0IcN32i-jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# "
      ],
      "metadata": {
        "id": "t_lZknyejKFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*download the VGG16 model and define the input data shape*###"
      ],
      "metadata": {
        "id": "JKTufFz518XV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the base model of VGG16 model\n",
        "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "WHV35vbdc9cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*- Converting data to tensors is necessary as tensors are the basic data structure used in TensorFlow and are required for building and training a machine learning model.*###\n",
        "\n",
        "###*- Normalizing the data by dividing it by 255.0 helps in scaling the values of the data between 0 and 1, which can help the model learn better.*###\n",
        "\n",
        "###*- One-hot encoding the labels transforms the labels into a binary matrix representation where each column corresponds to a single category. This encoding is needed for multiclass classification problems as it allows the model to predict the class of a sample by providing the probability of each class.*###"
      ],
      "metadata": {
        "id": "1mNX_IkR25xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "\n",
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "\n",
        "\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, len(breeds))\n",
        "y_test = to_categorical(y_test, len(breeds))\n"
      ],
      "metadata": {
        "id": "z_qsu17O5VOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*- This code block freezes the layers of the base VGG16 model, meaning that the weights of these layers will not be updated during training. This helps to prevent overfitting by retaining the pre-trained feature extraction capabilities of the base model.*###"
      ],
      "metadata": {
        "id": "jWKPXWNU3bgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the layers of the base model\n",
        "for layer in vgg16_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "C7KxCUrldAqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*- The code below creates a Sequential model in Keras.*###\n",
        "###*- The VGG16 model is then added on top of the base model by calling model.add(vgg16_model).*###\n",
        "###*- The Flatten layer is then added, which is used to flatten the multi-dimensional input from the previous layer into a one-dimensional array to be processed by the dense layers.*###\n",
        "###*- The first Dense layer is added with 256 units and ReLU activation. The number of units determines the dimensionality of the output space and ReLU activation is used for the activation function.*###\n",
        "###*- The Dropout layer is added with a rate of 0.5, which is used to prevent overfitting by randomly dropping some neurons during training.*###\n",
        "###*- The final Dense layer is added with the number of units equal to the number of different breeds and with a Softmax activation function. The Softmax activation function is used to ensure that the sum of all outputs is 1, so that the outputs can be interpreted as probabilities.*###\n",
        "###* -The model is then compiled by specifying the optimizer (Adam), loss function (categorical crossentropy), and evaluation metrics (accuracy).*###\n",
        "###* -A ModelCheckpoint is created to save the best model after each epoch during training.*###\n",
        "###* -Finally, the model is fit on the training data for 25 epochs with a batch size of 128, with the validation data and the ModelCheckpoint being passed to the fit method as arguments.*###\n",
        "\n",
        "## The softmax function, also known as softargmax[1]:‚Ää184‚Ää or normalized exponential function,[2]:‚Ää198‚Ää converts a vector of K real numbers into a probability distribution of K possible outcomes. It is a generalization of the logistic function to multiple dimensions, and used in multinomial logistic regression. The softmax function is often used as the last activation function of a neural network to normalize the output of a network to a probability distribution over predicted output classes, based on Luce's cho"
      ],
      "metadata": {
        "id": "TKuhhzet4Ujj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the VGG16 model on top of the base model\n",
        "model.add(vgg16_model)\n",
        "\n",
        "model.add(Flatten())\n",
        "# Add a Dense layer with 128 units and ReLU activation\n",
        "model.add(Dense(256, activation='relu'))\n",
        "# Add a Dropout layer with a rate of 0.5\n",
        "model.add(Dropout(0.5))\n",
        "# Add a Dense layer with the number of units equal to the number of breeds and Softmax activation\n",
        "model.add(Dense(len(breeds), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create a checkpoint to save the best model\n",
        "checkpoint = ModelCheckpoint(model_dir+'best_model.h5', save_best_only=True)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model.fit(X_train, y_train, epochs=25, batch_size=128, validation_data=(X_test, y_test), callbacks=[checkpoint])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYQBCkDKdGBA",
        "outputId": "045f7bce-b807-4346-8d04-484028143d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "16/16 [==============================] - 43s 2s/step - loss: 3.7221 - accuracy: 0.1627 - val_loss: 2.1072 - val_accuracy: 0.3380\n",
            "Epoch 2/25\n",
            "16/16 [==============================] - 12s 732ms/step - loss: 1.9568 - accuracy: 0.3258 - val_loss: 1.7902 - val_accuracy: 0.4792\n",
            "Epoch 3/25\n",
            "16/16 [==============================] - 12s 735ms/step - loss: 1.6473 - accuracy: 0.4297 - val_loss: 1.5293 - val_accuracy: 0.5346\n",
            "Epoch 4/25\n",
            "16/16 [==============================] - 12s 737ms/step - loss: 1.3988 - accuracy: 0.5272 - val_loss: 1.3262 - val_accuracy: 0.6011\n",
            "Epoch 5/25\n",
            "16/16 [==============================] - 12s 736ms/step - loss: 1.2034 - accuracy: 0.5948 - val_loss: 1.2531 - val_accuracy: 0.6482\n",
            "Epoch 6/25\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 1.0827 - accuracy: 0.6306 - val_loss: 1.1367 - val_accuracy: 0.6537\n",
            "Epoch 7/25\n",
            "16/16 [==============================] - 12s 748ms/step - loss: 0.9204 - accuracy: 0.6997 - val_loss: 1.0670 - val_accuracy: 0.6759\n",
            "Epoch 8/25\n",
            "16/16 [==============================] - 12s 750ms/step - loss: 0.8406 - accuracy: 0.7281 - val_loss: 1.0250 - val_accuracy: 0.6731\n",
            "Epoch 9/25\n",
            "16/16 [==============================] - 12s 750ms/step - loss: 0.7502 - accuracy: 0.7599 - val_loss: 0.9818 - val_accuracy: 0.6537\n",
            "Epoch 10/25\n",
            "16/16 [==============================] - 12s 771ms/step - loss: 0.6709 - accuracy: 0.7849 - val_loss: 0.9364 - val_accuracy: 0.6565\n",
            "Epoch 11/25\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.6502 - accuracy: 0.7883 - val_loss: 0.9132 - val_accuracy: 0.6870\n",
            "Epoch 12/25\n",
            "16/16 [==============================] - 12s 735ms/step - loss: 0.6000 - accuracy: 0.8172 - val_loss: 0.9426 - val_accuracy: 0.6731\n",
            "Epoch 13/25\n",
            "16/16 [==============================] - 12s 763ms/step - loss: 0.5201 - accuracy: 0.8403 - val_loss: 0.8878 - val_accuracy: 0.6787\n",
            "Epoch 14/25\n",
            "16/16 [==============================] - 12s 738ms/step - loss: 0.4837 - accuracy: 0.8422 - val_loss: 0.8916 - val_accuracy: 0.6842\n",
            "Epoch 15/25\n",
            "16/16 [==============================] - 12s 740ms/step - loss: 0.4555 - accuracy: 0.8569 - val_loss: 0.9140 - val_accuracy: 0.6898\n",
            "Epoch 16/25\n",
            "16/16 [==============================] - 13s 833ms/step - loss: 0.4425 - accuracy: 0.8697 - val_loss: 0.8619 - val_accuracy: 0.7036\n",
            "Epoch 17/25\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.3911 - accuracy: 0.8697 - val_loss: 0.8654 - val_accuracy: 0.6953\n",
            "Epoch 18/25\n",
            "16/16 [==============================] - 12s 752ms/step - loss: 0.3750 - accuracy: 0.8854 - val_loss: 0.8661 - val_accuracy: 0.6925\n",
            "Epoch 19/25\n",
            "16/16 [==============================] - 12s 753ms/step - loss: 0.3640 - accuracy: 0.8868 - val_loss: 0.8620 - val_accuracy: 0.6953\n",
            "Epoch 20/25\n",
            "16/16 [==============================] - 13s 840ms/step - loss: 0.3591 - accuracy: 0.8809 - val_loss: 0.8570 - val_accuracy: 0.6981\n",
            "Epoch 21/25\n",
            "16/16 [==============================] - 12s 742ms/step - loss: 0.3227 - accuracy: 0.8986 - val_loss: 0.8796 - val_accuracy: 0.6814\n",
            "Epoch 22/25\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.3009 - accuracy: 0.9079 - val_loss: 0.8713 - val_accuracy: 0.6870\n",
            "Epoch 23/25\n",
            "16/16 [==============================] - 12s 743ms/step - loss: 0.2962 - accuracy: 0.9079 - val_loss: 0.8685 - val_accuracy: 0.6814\n",
            "Epoch 24/25\n",
            "16/16 [==============================] - 12s 747ms/step - loss: 0.2765 - accuracy: 0.9074 - val_loss: 0.8730 - val_accuracy: 0.6870\n",
            "Epoch 25/25\n",
            "16/16 [==============================] - 12s 746ms/step - loss: 0.2677 - accuracy: 0.9157 - val_loss: 0.8662 - val_accuracy: 0.6953\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b50337ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*Loading the model to use in predicting some images*###"
      ],
      "metadata": {
        "id": "Y93nZuii42wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "IIqfSt5kun9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the best model\n",
        "model = load_model('/content/drive/MyDrive/Test_the_Keras/Projecto/best_model.h5')\n"
      ],
      "metadata": {
        "id": "8yg4S4bwtxVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*loading the images for whihc I want to get the breed*###"
      ],
      "metadata": {
        "id": "EkfobOFC5IgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the image you want to classify\n",
        "# Birman\n",
        "img9 = cv2.imread('/content/drive/MyDrive/Test_the_Keras/Projecto/CATS 2/Birman_79.jpg')\n",
        "# Bengal\n",
        "img2 = cv2.imread('/content/drive/MyDrive/Test_the_Keras/Projecto/CATS 2/Bengal_60.jpg')\n",
        "#Bombay \n",
        "img3 = cv2.imread('/content/drive/MyDrive/Test_the_Keras/Projecto/CATS 2/Bombay_183.jpg')\n",
        "#British\n",
        "img4 = cv2.imread('/content/drive/MyDrive/Test_the_Keras/Projecto/CATS 2/British_Shorthair_45.jpg')\n",
        "#Leia\n",
        "img5 = cv2.imread('/content/drive/MyDrive/Test_the_Keras/Projecto/British_Shortair_150.jpg')\n"
      ],
      "metadata": {
        "id": "2ilsTio-5Haf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W19ls7ez0yp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*Defined a function for finding the breed*###"
      ],
      "metadata": {
        "id": "WdmZBJea5eYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_breed(model, image):\n",
        "  \n",
        "  #Convert the image to a numpy array\n",
        "  img = cv2.resize(image, (224, 224))\n",
        "  \n",
        "  #Expand the dimensions of the image to (1, 224, 224, 3)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  \n",
        "  result_prob = model.predict(img)\n",
        "  result = result_prob.argmax(axis=-1)\n",
        "\n",
        "  predicted_class_index = np.argmax(result_prob)\n",
        "\n",
        "  #Get the label of the predicted breed\n",
        "  predicted_breed = breeds[predicted_class_index]\n",
        "\n",
        "\n",
        "\n",
        "  print(f\"The predicted breed is : {predicted_breed}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xsHRtvYVS48s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_EL7VO3S5lV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# should predict Abyssinian\n",
        "predict_breed(model,img9)\n",
        "# should predict Bengal\n",
        "predict_breed(model,img2)\n",
        "# Should predict Bombay\n",
        "predict_breed(model,img3)\n",
        "# Should predict British_shortair\n",
        "predict_breed(model,img4)\n",
        "#\n",
        "predict_breed(model,img5)"
      ],
      "metadata": {
        "id": "Te6xJf8QcFH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a78732-6736-4391-c4f4-5be6a6272b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "The predicted breed is : Birman\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "The predicted breed is : Bengal\n",
            "\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "The predicted breed is : Bombay\n",
            "\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "The predicted breed is : Bengal\n",
            "\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "The predicted breed is : Birman\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*In conclusion, atleast for the cases tried so far the model seems to be predicting the correct breed*###\n",
        "###*However please note that the model accuracy is approximately 70% hance it is bound to make some mistakes in general*###"
      ],
      "metadata": {
        "id": "k38-XCid5_02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### As you can see it identify a British short air as a Bengal\n"
      ],
      "metadata": {
        "id": "O5jaMnTw0hxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "B03oRz_-3sNd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "txKIz0Qr6Wtm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}